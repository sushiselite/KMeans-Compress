{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Getting the Dataset and Assigning Variables\n",
    "\n",
    "In this step, we load the base image that we wanted to compress and use a combination of `pandas` and the `Image` from `Pillow` to create a dataset. We also assign its `width` and `height` to store details about the image size and load the RGB data of each pixel of the base image into a NumPy array to fit into a KMeans cluster model in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 192)\n"
     ]
    }
   ],
   "source": [
    "# Read the image\n",
    "colourImg = Image.open(\"base.jpg\")\n",
    "\n",
    "# Convert the image to a NumPy array of pixels\n",
    "colourPixels = colourImg.convert(\"RGB\")\n",
    "colourArray = np.array(colourPixels.getdata())\n",
    "\n",
    "# Convert the NumPy array to a DataFrame\n",
    "df = pd.DataFrame(colourArray, columns=[\"red\",\"green\",\"blue\"])\n",
    "\n",
    "# Save the DataFrame to a txt file to be used as a dataset\n",
    "np.savetxt('datasetRGB.txt', df.values, fmt='%d')\n",
    "\n",
    "\n",
    "data = np.loadtxt('datasetRGB.txt')  # Load the RGB pixel data from the file into a NumPy array\n",
    "im = Image.open(\"base.jpg\")\n",
    "print(im.size)\n",
    "width, height = im.size # Get the width and height of the image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Modelling\n",
    "\n",
    "In this step, we use the in-built `KMeans` library algorithm to create KMeans clusters to compress our image by `clustering the RGB values` from the  dataset we created earlier. The number of clusters, or ***`k`***, can also be considered to be the `number of colors`. To explain it simply, consider that our base image (the image we want to compress) has ***`n`*** colors. Now, by assigning a value to ***`k`***, we are reducing the ***`n`*** colors to ***`k`*** colors with the help of clustering. A higher value of ***`k`*** will lead to a better quality image and a lower loss of colors. However, it will also lead to a smaller difference between the sizes of the actual and the compressed images. In the next section of this notebook, there are a few examples demonstrating the same concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Advay\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=16, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=16, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=16, random_state=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 16  # Number of clusters for compression\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)  # Create a KMeans object\n",
    "kmeans.fit(data)  # Perform K-means clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Output the Compressed Image\n",
    "\n",
    "Now that we have formed our clusters, we get the `cluster labels` for each of the pixels and then proceed to compress the image by `replacing each pixel with the centroid of the cluster it was assigned to`. We then reshape the compressed data that now consists of replaced pixels, so that it equals the size of our base image. We then convert each of the data values into an `8-bit unsigned integer` as it ranges from 0 to 255, and is often used to represent the respective RGB color channels. Finally, we use `Pillow` once more to convert our data into an Image object and can now output in a format that fits our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_  # Get the cluster labels for each pixel\n",
    "compressed_data = kmeans.cluster_centers_[labels]  # Replace pixel values with centroid values\n",
    "\n",
    "# Reshape the compressed image to match the original image\n",
    "compressed_image = np.reshape(compressed_data, (height, width, 3))\n",
    "\n",
    "# Convert the NumPy array to an image\n",
    "compressed_image = compressed_image.astype(np.uint8) \n",
    "compressed_image = Image.fromarray(compressed_image)  # Create a PIL Image object\n",
    "\n",
    "# Save the image as jpg in the current directory\n",
    "compressed_image.save('compressed_image.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
